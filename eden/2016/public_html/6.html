<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><!--This file was converted to xhtml by OpenOffice.org - see http://xml.openoffice.org/odf2xhtml for more info.--><head profile="http://dublincore.org/documents/dcmi-terms/"><meta http-equiv="Content-Type" content="application/xhtml+xml; charset=utf-8"/><title xml:lang="en-US">- no title specified</title><meta name="DCTERMS.title" content="" xml:lang="en-US"/><meta name="DCTERMS.language" content="en-US" scheme="DCTERMS.RFC4646"/><meta name="DCTERMS.source" content="http://xml.openoffice.org/odf2xhtml"/><meta name="DCTERMS.issued" content="2015-10-11T19:59:50.50" scheme="DCTERMS.W3CDTF"/><meta name="DCTERMS.modified" content="2015-10-12T14:17:01.58" scheme="DCTERMS.W3CDTF"/><meta name="DCTERMS.provenance" content="" xml:lang="en-US"/><meta name="DCTERMS.subject" content="," xml:lang="en-US"/><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/" hreflang="en"/><link rel="schema.DCTERMS" href="http://purl.org/dc/terms/" hreflang="en"/><link rel="schema.DCTYPE" href="http://purl.org/dc/dcmitype/" hreflang="en"/><link rel="schema.DCAM" href="http://purl.org/dc/dcam/" hreflang="en"/><style type="text/css">
	@page {  }
	table { border-collapse:collapse; border-spacing:0; empty-cells:show }
	td, th { vertical-align:top; font-size:12pt;}
	h1, h2, h3, h4, h5, h6 { clear:both }
	ol, ul { margin:0; padding:0;}
	li { list-style: none; margin:0; padding:0;}
	<!-- "li span.odfLiEnd" - IE 7 issue-->
	li span. { clear: both; line-height:0; width:0; height:0; margin:0; padding:0; }
	span.footnodeNumber { padding-right:1em; }
	span.annotation_style_by_filter { font-size:95%; font-family:Arial; background-color:#fff000;  margin:0; border:0; padding:0;  }
	* { margin:0;}
	.P1 { font-size:12pt; font-family:Times New Roman; writing-mode:page; }
	.P2 { font-size:12pt; font-family:Times New Roman; writing-mode:page; }
	.P3 { font-size:12pt; font-family:Times New Roman; writing-mode:page; font-weight:normal; }
	.Bullet_20_Symbols { font-family:OpenSymbol; }
	.T1 { vertical-align:sub; font-size:58%;}
	.T2 { vertical-align:sub; font-size:58%;font-weight:normal; }
	.T3 { vertical-align:sub; font-size:58%;font-weight:bold; }
	.T4 { font-weight:bold; }
	.T5 { font-weight:normal; }
	<!-- ODF styles with no properties representable as CSS -->
	{ }
	</style></head><body dir="ltr" style="max-width:8.5in;margin:0.7874in; margin-top:0.7874in; margin-bottom:0.7874in; margin-left:0.7874in; margin-right:0.7874in; "><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>CPU Scheduling<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>What and Why?<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Why?<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>At first, was to share an expensive resource via multiprogramming<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Now to perform concurrent tasks because the processor is powerful enough<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Future looks like the past as well as now<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Computing utility – large data/processing centers use multiprogramming to maximize resource utilization<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Systems still powerful enough for each user to run multiple concurrent tasks<span class="odfLiEnd"/> </p></li></ul></li></ul></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Assumptions<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Pool of jobs contending for the CPU<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Jobs are independent and compete for resources<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Not true for all systems/scenarios<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Scheduler mediates between jobs to optimize some performance criterion<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>What do we optimize?<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>System oriented metrics<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Processor utilization: percentage of time the processor is busy<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Throughput: number of processes completed per unit of time<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>User oriented metrics<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Turnaround time: interval of time between submission and termination (including any time spent waiting)<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Appropriate for batch jobs<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Response time: for interactive jobs, time from the submission of a request until the response begins to be received<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Deadlines: when process completion deadlines are specified, the percentage of deadlines met must be promoted<span class="odfLiEnd"/> </p></li></ul></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Design space<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Two dimensions<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Selection function<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Which of the ready jobs should be run next?<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Preemption<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Preemptive: currently running job may be interrupted and moved to ready state<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Non-preemptive: once a process is in running state, it continues to execute until it terminates or blocks<span class="odfLiEnd"/> </p></li></ul></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Job Behavior<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>IO Bound Jobs<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Perform lots of IO, tend to have short CPU bursts<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>CPU Bound Jobs<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Perform very little IO, have very long CPU bursts<span class="odfLiEnd"/> </p></li></ul></li></ul></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Short term CPU Scheduler<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Select from among the processes in memory that are ready to execute, allocate the CPU to one of them<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>CPU scheduling decisions may take place when a process:<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Switches from running to waiting<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Switches from running to ready<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Switches from waiting to ready<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Terminates<span class="odfLiEnd"/> </p></li></ul></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Dispatcher<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>The dispatcher module gives control of the CPU to the process selected by the short term scheduler, which involves:<span class="odfLiEnd"/> </p><ul><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Switching context<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Switching to user mode<span class="odfLiEnd"/> </p></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Jumping to the proper location in the user program to restart that program<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Dispatch latency – the time it takes for the dispatcher to stop one process and start another running<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P1" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>First Come First Served (FCFS) Scheduling<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Example:<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>P1 → burst time 24, P2 → bt 3, P3 → bt 3<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>If they arrive in sequential order (1, 2, 3)...<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Waiting time for P1 = 0, P2 = 24, P3 = 27<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Average wait = (0 + 24 + 27)/3 = 17<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>If they arrive in the order 2, 3, 1...<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Waiting time for P1 = 6, p2 = 0, p3 = 3<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Average wait = (6 + 0 + 3)/3 = 3<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Better than previous case<span class="odfLiEnd"/> </p></li></ul></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Convoy Effect: when short processes are executed behind a long process<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Shortest Job First (SJF) Scheduling<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Associate with each process the length of it's next CPU burst<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Use these lengths to schedule the shortest process first<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Two schemes:<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Non-preemptive<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Once CPU given to the process, it cannot be preempted until it completes its CPU burst<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Preemptive<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>If a new process arrives with CPU burst length less than remaining time of current executing process, preempt. This scheme is known as the Shortest Remaining Time First (SRTF)<span class="odfLiEnd"/> </p></li></ul></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>SJF is optimal – gives minimum average waiting time for a given set of processes<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Non-preemptive SJF<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>P1 → arrival 0.0 → burst 7, P2 → 2.0 → 4, P3 → 4.0 → 1, P4 → 5.0 → 4<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>If they arrive in order 1, 3, 2, 4...<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Average waiting time = (0 + 6 + 3 + 7)/4 = 4<span class="odfLiEnd"/> </p></li></ul></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Preemptive SJF<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>P1 → arrival 0.0 → burst 7, P2 → 2.0 → 4, P3 → 4.0 → 1, P4 → 5.0 → 4<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>If they arrive in the order 1, 3, 2, 4<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Average waiting time = (9 + 1 + 0 + 2)/4 = 3<span class="odfLiEnd"/> </p></li></ul></li></ul></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Determining length of next CPU Burst<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Can only estimate the length<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Can be done by using the length of previous CPU bursts, using exponential averaging<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>t<span class="T1">n</span> = actual length of nth CPU burst<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>T<span class="T1">n+1</span> = predicted value for the next CPU burst<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>a, 0 &lt;= a &lt;= 1<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Define:<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>T<span class="T1">n+1</span> = a t<span class="T1">n</span> + (1-a)T<span class="T1">n</span><span class="odfLiEnd"/> </p></li></ul></li></ul></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Round Robin (RR)<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Each process gets a small unit of CPU time (time quantum), usually 1-50 ms. After this time has elapsed, the process is preempted and added to the end of the ready queue<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>If there are n processes in the ready queue and the time quantum is q, then each process gets 1/n of the CPU time in chunks of at most q time units at once. No process waits more than (n-1)q time units<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Performance<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Large q → First in first out<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Small q → q must be large with respect to context switch, otherwise overhead is too high<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Typically higher average turnaround than SJF, but better response time<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Priority Scheduling<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>A priority number (integer) is associated with each process<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>The CPU is allocated to the process with the highest priority (smaller integer, higher priority)<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Preemptive<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Non-preemptive<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>SJF is a priority scheduling policy where priority is the predicted next CPU burst time<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Problem = starvation – low priority processes may never execute<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Solution = aging – as time progresses increase the priority of the process<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Multilevel Queue<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Ready queue is partitioned into separate queues<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Foreground (interactive) and background (batch)<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Each queue has it's own scheduling algorithm<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Foreground (RR), background (FCFS)<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Scheduling must be done between the queues<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Fixed priority scheduling: serve all from foreground, then from background<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>High possibility of starvation<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Time slice: each queue gets a certain amount of CPU time which it can schedule amongst its processes<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>ie: 80% to foreground in RR, 20% to background in FCFS<span class="odfLiEnd"/> </p></li></ul></li></ul></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Multilevel Feedback Queue<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>A process can move between various queues, and aging can be implemented this way<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Multilevel Feedback Queue scheduler defined by the following parameters:<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Number of queues<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Scheduling algorithms for each queue<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Method used to determine when to upgrade/demote a process<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Method used to determine which queue a process will enter when that process needs service<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Example: three queues<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Q<span class="T5">0 → time quantum 8ms, Q1 → time quantum 16ms, Q2 → FCFS</span><span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>A new job enters Q0, if it doesn't finish in 8ms, it goes to queue Q1, if it doesn't finish in 16ms when it reaches Q1,it is preempted and moved to Q2 where the job is scheduled according to FCFS<span class="odfLiEnd"/> </p></li></ul></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Traditional UNIX Scheduling<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Multilevel feedback queues<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>128 priorities possible, 0-127. 0 is the highest importance<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>1 Round Robin queue per priority<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>At every scheduling event, the scheduler picks the highest priority non-empty queue, and runs jobs in round-robin (HIGH PRIORITY = LOW Q#)<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Scheduling events<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Clock interrupt → process gives up CPU → IO completion → process termination<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>All processes assigned a baseline priority based on the type and current execution status<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>At scheduling events, all process priorities are adjusted based on the amount of CPU used, the current load, and how long the process has been waiting<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Most processes are not running/ready, so lots of computing shortcuts are used when computing new priorities<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>UNIX Priority Calculation<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Every 4 clock ticks a process priority is updated:<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Priority = Baseline + [utilization/4] + 2NiceFactor<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>The utilization is incremented by 1 every clock tick during which the process is running<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>The NiceFactor allows some control of job priority. It can be set from -20 to 20<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Jobs using a lot of CPU increase the priority value. Interactive jobs not using much CPU will return to the baseline<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Very long running CPU bound jobs will get “stuck” at lowest priority, causing them to run infrequently<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Decay function used to weight utilization to recent CPU usage<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>A process's utilization at time t is decayed every second:<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span><span class="T5">u</span><span class="T2">t</span><span class="T3"> </span><span class="T4">= </span><span class="T5">[2load/(2load + 1)] * u</span><span class="T2">(t – 1)</span><span class="T5"> + NiceFactor</span><span class="odfLiEnd"/> </p></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>The system wide load is the average number of runnable jobs during the last 1 second<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Example:<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>1 job on CPU, Load will be 1, NF is 0: <span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>at +1 sec: U1 = 2/3 U0<br/><span style="margin-left:0cm"/>at +2 sec: U2 = 2/3 U1 + 2/3 U0 = 2/3 U1 + (2/3)^2U0<span class="odfLiEnd"/> </p></li></ul></li></ul></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>UNIX Priority Reset<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>When a process transitions from blocked to ready state, its priority is set as follows:<span class="odfLiEnd"/> </p><ul><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span><span class="T5">u</span><span class="T2">t</span><span class="T5"> = [(2load)/(2load + 1)]^tblocked *u</span><span class="T2">(t -1 )</span><span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>tblocked = time a process was blocked<span class="odfLiEnd"/> </p></li></ul></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Scheduling Algorithms<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>FIFO/FCFS is simple, leads to poor average turnaround times. Short processes are delayed by long processes that arrive before them<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>SJN and SRT alleviate the problem with FIFO, but require information on the length (service time) of each process. This information is not always available, though it can sometimes be approximated based on past history or user input<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>RR achieves good response times, but favors CPU-bound jobs which have longer CPU bursts<span class="odfLiEnd"/> </p></li><li><p class="P2" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span><span class="T5">Feedback achieves good response times without info on process length, but more </span><span class="T5">complex than RR</span><span class="odfLiEnd"/> </p></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Multiprocessor Scheduling<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Several different possibilities <span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Load sharing – an idle processor takes the first process out of the ready queue and runs it. Is this a good idea? How can we improve it?<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Poor locality, poor synchronization behavior<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Simple, good processor utilization. Affinity or per processor queues can improve the locality issue<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Gang scheduling – all processes/threads of each application are scheduled together. Why is this good? Any difficulties?<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Central control, fragmentation, unnecessary processor idle times (two processors with P/2 + 1 threads)<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Good synchronization behavior, if careful. Good locality.<span class="odfLiEnd"/> </p></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Hardware partitions – applications get different parts of the machine. Any problems here?<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Poor utilization for IO intensive applications. Fragmentation – unnecessary processor idle times when partitions left are small<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Excellent locality and synchronization behavior<span class="odfLiEnd"/> </p></li></ul></li></ul></li></ul></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">◦</span>Network Queuing Models<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Queuing theory lets us predict avg length of queues, # jobs vs service time<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">▪</span>Little's Law<span class="odfLiEnd"/> </p><ul><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Mean # jobs in system = arrival rate x mean response time<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Mean # jobs in queue = arrival rate x mean waiting time<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span># of jobs in system = # jobs in queue + # jobs being serviced<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Response time = waiting + service<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Waiting time = time between arrival and service<span class="odfLiEnd"/> </p></li><li><p class="P3" style="margin-left:0cm;"><span class="Bullet_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>Stability condition: mean arrival rate &lt; #servers x mean service rate per server<span class="odfLiEnd"/> </p></li></ul></li></ul></li></ul></li></ul></body></html>